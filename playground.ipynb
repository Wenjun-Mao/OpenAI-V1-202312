{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def create_expanded_and_mask_images(base_image_path, res):\n",
    "    \"\"\"\n",
    "    Function to create an expanded image with a white background and a mask image.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_image_path: str, the path to the base image.\n",
    "    - res: int, resolution of the output images, can be 256, 512, or 1024.\n",
    "    \n",
    "    Returns:\n",
    "    - expanded_image_path: str, the path to the expanded image.\n",
    "    - correct_mask_image_path: str, the path to the mask image.\n",
    "    \"\"\"\n",
    "    # Validate the resolution\n",
    "    if res not in [256, 512, 1024]:\n",
    "        raise ValueError(\"Resolution must be one of 256, 512, or 1024.\")\n",
    "    \n",
    "    # Load the image\n",
    "    base_image = Image.open(base_image_path)\n",
    "\n",
    "    # Create a new image with white background and the specified resolution\n",
    "    new_image = Image.new(\"RGB\", (res, res), \"white\")\n",
    "    new_image.paste(base_image, (int((res - base_image.width) / 2), int((res - base_image.height) / 2)))\n",
    "\n",
    "    # Save the new image as PNG\n",
    "    expanded_image_path = f'expanded_base_{res}.png'\n",
    "    new_image.save(expanded_image_path, \"PNG\")\n",
    "\n",
    "    # Create a mask with transparent areas where the original image is not present\n",
    "    base_mask = base_image.split()[-1].point(lambda x: 255 if x > 0 else 0)\n",
    "    correct_mask = Image.new(\"RGBA\", (res, res), (0, 0, 0, 0))\n",
    "    correct_mask.paste(base_mask, (int((res - base_image.width) / 2), int((res - base_image.height) / 2)), mask=base_mask)\n",
    "\n",
    "    # Save the correct mask image\n",
    "    correct_mask_image_path = f'mask_base_{res}.png'\n",
    "    correct_mask.save(correct_mask_image_path, \"PNG\")\n",
    "    \n",
    "    return expanded_image_path, correct_mask_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('expanded_base_1024.png', 'mask_base_1024.png')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_expanded_and_mask_images('base.png', 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "\n",
    "# OpenAI API Key\n",
    "api_key = client.api_key\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"base2.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_desc(image_path):\n",
    "    \"\"\"\n",
    "    Function to get the image description from the OpenAI API.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: str, the path to the image.\n",
    "    \n",
    "    Returns:\n",
    "    - img_desc: str, the image description.\n",
    "    \"\"\"\n",
    "    # Encode the image\n",
    "    base64_image = encode_image(image_path)\n",
    "    \n",
    "    # Set the headers\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    # Set the payload\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"What's in the image, do not use full sentences, just describe the objects, ingore any watermarks or text on the image.\"\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                \"detail\": \"low\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 65\n",
    "    }\n",
    "    \n",
    "    # Send the request\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    \n",
    "    # Get the image description\n",
    "    img_desc = response.json()['choices'][0]['message']['content']\n",
    "    \n",
    "    return img_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Person, red puffer jacket, striped garment, light-colored hair, white background, decorative red item.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_img_desc('base.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expanded_img_url():\n",
    "  pics = client.images.edit(\n",
    "    image=open(\"expanded_base_1024.png\", \"rb\"),\n",
    "    mask=open(\"mask_base_1024.png\", \"rb\"),\n",
    "    prompt=\"Person, red puffer jacket, striped garment, light-colored hair, white background, decorative red item\",\n",
    "    n=1,\n",
    "    size=\"1024x1024\"\n",
    "  )\n",
    "\n",
    "  url = pics.data[0].url\n",
    "\n",
    "  return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics = get_expanded_img_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImagesResponse(created=1703467173, data=[Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-BMyObFCyK3Rb8g2wkaYeYu12/user-CRJfQDcVUQTJQmD4Vv1PSyQL/img-Od80zYXe9j3hUFRsm2fNfZ7m.png?st=2023-12-25T00%3A19%3A33Z&se=2023-12-25T02%3A19%3A33Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-24T08%3A59%3A51Z&ske=2023-12-25T08%3A59%3A51Z&sks=b&skv=2021-08-06&sig=9XsofbDsMLTyE0OKM9QuJ4B6iaHwKXeiq5sGOpVPQ1g%3D')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-BMyObFCyK3Rb8g2wkaYeYu12/user-CRJfQDcVUQTJQmD4Vv1PSyQL/img-Od80zYXe9j3hUFRsm2fNfZ7m.png?st=2023-12-25T00%3A19%3A33Z&se=2023-12-25T02%3A19%3A33Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-24T08%3A59%3A51Z&ske=2023-12-25T08%3A59%3A51Z&sks=b&skv=2021-08-06&sig=9XsofbDsMLTyE0OKM9QuJ4B6iaHwKXeiq5sGOpVPQ1g%3D'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'response' is your response object\n",
    "url = pics.data[0].url\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_openaiv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
