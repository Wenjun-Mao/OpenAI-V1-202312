{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "client.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def create_expanded_and_mask_images(base_image_path, res):\n",
    "    \"\"\"\n",
    "    Function to create an expanded image with a white background and a mask image.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_image_path: str, the path to the base image.\n",
    "    - res: int, resolution of the output images, can be 256, 512, or 1024.\n",
    "    \n",
    "    Returns:\n",
    "    - expanded_image_path: str, the path to the expanded image.\n",
    "    - correct_mask_image_path: str, the path to the mask image.\n",
    "    \"\"\"\n",
    "    # Validate the resolution\n",
    "    if res not in [256, 512, 1024]:\n",
    "        raise ValueError(\"Resolution must be one of 256, 512, or 1024.\")\n",
    "    \n",
    "    # Load the image\n",
    "    base_image = Image.open(base_image_path)\n",
    "\n",
    "    # Create a new image with white background and the specified resolution\n",
    "    new_image = Image.new(\"RGB\", (res, res), \"white\")\n",
    "    new_image.paste(base_image, (int((res - base_image.width) / 2), int((res - base_image.height) / 2)))\n",
    "\n",
    "    # Save the new image as PNG\n",
    "    expanded_image_path = f'expanded_base_{res}.png'\n",
    "    new_image.save(expanded_image_path, \"PNG\")\n",
    "\n",
    "    # Create a mask with transparent areas where the original image is not present\n",
    "    base_mask = base_image.split()[-1].point(lambda x: 255 if x > 0 else 0)\n",
    "    correct_mask = Image.new(\"RGBA\", (res, res), (0, 0, 0, 0))\n",
    "    correct_mask.paste(base_mask, (int((res - base_image.width) / 2), int((res - base_image.height) / 2)), mask=base_mask)\n",
    "\n",
    "    # Save the correct mask image\n",
    "    correct_mask_image_path = f'mask_base_{res}.png'\n",
    "    correct_mask.save(correct_mask_image_path, \"PNG\")\n",
    "    \n",
    "    return expanded_image_path, correct_mask_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('expanded_base_1024.png', 'mask_base_1024.png')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_expanded_and_mask_images('base2.png', 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8WxU87JNbvuivZSic2VwfN9ycWRRf', 'object': 'chat.completion', 'created': 1702865848, 'model': 'gpt-4-1106-vision-preview', 'usage': {'prompt_tokens': 800, 'completion_tokens': 22, 'total_tokens': 822}, 'choices': [{'message': {'role': 'assistant', 'content': 'Sphinx statue, bird in flight, futuristic cityscape, skyscrapers, clouds, reflective water surface.'}, 'finish_reason': 'stop', 'index': 0}]}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "\n",
    "# OpenAI API Key\n",
    "api_key = client.api_key\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"base2.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4-vision-preview\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What's in the image, do not use full sentences, just describe the objects, ingore any watermarks or text on the image.\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 50\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pics = client.images.edit(\n",
    "  image=open(\"expanded_base_1024.png\", \"rb\"),\n",
    "  mask=open(\"mask_base_1024.png\", \"rb\"),\n",
    "  # prompt=\"A young adult male with light blonde hair and a gentle expression, wearing a vibrant red puffer jacket over a black and white striped shirt\",\n",
    "  prompt=\"Sphinx statue, bird in flight, futuristic cityscape, skyscrapers, clouds, reflective water surface\",\n",
    "  n=2,\n",
    "  size=\"1024x1024\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImagesResponse(created=1702865885, data=[Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-BMyObFCyK3Rb8g2wkaYeYu12/user-CRJfQDcVUQTJQmD4Vv1PSyQL/img-aYy1jGRl8m7s3gnfNzJmRI7q.png?st=2023-12-18T01%3A18%3A04Z&se=2023-12-18T03%3A18%3A04Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-17T18%3A52%3A37Z&ske=2023-12-18T18%3A52%3A37Z&sks=b&skv=2021-08-06&sig=Di1R/WLNH/X7c9F35bX1qTsZiPDSy2zomMUwm9mn/yA%3D'), Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-BMyObFCyK3Rb8g2wkaYeYu12/user-CRJfQDcVUQTJQmD4Vv1PSyQL/img-RWG0z9M1ZmwKEYB8sexJ7vOw.png?st=2023-12-18T01%3A18%3A05Z&se=2023-12-18T03%3A18%3A05Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-17T18%3A52%3A37Z&ske=2023-12-18T18%3A52%3A37Z&sks=b&skv=2021-08-06&sig=on/YzLy9Hyc3vIUMm1xh82sP0AoS4RVAXDqIWyvEBsQ%3D')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_openaiv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
